<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi</title>
<meta content="Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi" name="title"/>
<meta content="Koskaan ei voi taata, ettei tekoäly tuota hirvittäviä sivuvaikutuksia, mutta Facebookin rotusyrjintähistoria tekee todennäköiseksi, että tämä virhe ei jää heidän viimeisekseen." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi" property="og:title"/>
<meta content="Koskaan ei voi taata, ettei tekoäly tuota hirvittäviä sivuvaikutuksia, mutta Facebookin rotusyrjintähistoria tekee todennäköiseksi, että tämä virhe ei jää heidän viimeisekseen." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi" property="twitter:title"/>
<meta content="Koskaan ei voi taata, ettei tekoäly tuota hirvittäviä sivuvaikutuksia, mutta Facebookin rotusyrjintähistoria tekee todennäköiseksi, että tämä virhe ei jää heidän viimeisekseen." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Etusivu</a>
<a href="../rights.html">Digitaaliset oikeudet</a>
<a href="index.html">Artikkelit</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<section class="simple-orange">
<article class="essay-title">
<h1>Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi</h1>
<p>Tämä on aito artikkeli, jonka on kirjoittanut <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Arvioitu lukuaika: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section class="simple-gray flex-container">
<article class="blog">
<h1>Facebook pyytää anteeksi mustien miesten luokittelua kädellisiksi ihmisiksi</h1>
<p>Tekoälyillä voi olla rodullisia ennakkoluuloja. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Kaukasialaiset kasvot tunnistetaan ja tunnistetaan 10-100 kertaa todennäköisemmin oikein</a> kuin afroamerikkalaiset ja aasialaiset kasvot, mikä on jo johtanut <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">vääriin syytöksiin, pidätyksiin ja jopa vangitsemisiin</a>, koska tekoäly ei osannut oikein yhdistää ei-valkoisia kasvoja.</p>
<p>Monet opiskelijat ovat kokeneet tämän omakohtaisesti pandemian aikana. Monet yritykset, kuten <a href="https://proctorio.com/" target="_blank">Proctorio</a>, ovat tehneet suuria menestyksiä yliopistoissa ja kouluissa, joissa opettajat ohjeistavat oppilaitaan asentamaan ohjelmiston, joka tarkistaa, tekevätkö he kokeen rehellisesti. Ohjelmisto syytti todennäköisemmin värillisiä ihmisiä huijaamisesta, koska <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">ohjelmisto ei tunnistanut heidän kasvojaan</a>. Tällaisten koetarkastajien ohjelmistojen on osoitettu <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">vahvistavan valkoista ylivaltaa, seksismiä, ableismiä ja transfobiaa</a>.</p>
<h2>Facebookin virhe</h2>
<p>Facebookin anteeksipyyntö koski <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">New York Timesin</a> mukaan mustia miehiä, jotka olivat joutuneet yhteenottoihin valkoisten siviilien ja poliisien kanssa. Kuvantunnistus tekoäly luokitteli klipit apinoita tai kädellisiä esittäviksi kuviksi, vaikka videoilla ei ollut mitään tekemistä kummankaan kanssa.</p>
<p>Miten tämä tapahtuu? Tekoälyn ennakkoluuloisuus on yleensä seurausta ennakkoluuloisesta koulutusjoukosta. Kuten Joy Buolamwini selittää <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">TED-puheessaan</a>, jossa hän kertoo, miten kasvojentunnistusohjelma ei tunnistanut hänen kasvojaan. Samalla tavalla aineistolla <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">jossa yli 80 prosenttia kasvoista on valkoisia</a> voi olla vaikeampi tunnistaa erivärisiä ihmisiä ja se voi turvautua luokittelemaan nämä kasvot joksikin ihmistä lähellä olevaksi - kuten apinoiksi ja muiksi kädellisiksi.</p>
<p>Facebookin äskettäistä virhettä vastaava skandaali nähtiin vuonna 2015, kun Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">määritteli Google-kuvissa mustat ihmiset virheellisesti gorilloiksi</a>. Sen sijaan, että tekoälyä olisi muutettu, <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos kuitenkin poisti sanat "gorilla", "simpanssi", "simpanssi" ja "apina". Vaikka tämä tarkoittaa, että ihmisiä ei enää tunnisteta apinoiksi Google Photosissa, se viittaa siihen, että tekoälyn taustalla olevia ongelmia ei ole vielä korjattu.</a></p>
<h2>Facebookin rasistinen väärinkäytös</h2>
<p>Vaikka Facebookin tekoälyn virhe juontaa juurensa yhteiskunnallisella tasolla leikittelevästä ongelmasta, Facebookissa on tapahtunut väärinkäytöksiä, usein rasistisia.</p>
<ul>
<li>Instagram-käyttäjien, joiden toiminta viittasi mustiin, tilit poistettiin automaattisesti käytöstä 50 prosenttia todennäköisemmin. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Tutkijoita kehotettiin esimiehiltään lopettamaan tutkimus ja vaikenemaan siitä</a>;</li>
<li>Facebookin toimitusjohtaja Mark Zuckerbergin <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">piti julkisesti pyytää työntekijöitään lopettamaan Black Lives Matter -lauseiden yliviivaaminen</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">epäonnistui hillitsemään Englannin jalkapalloilijoiden rasistisia loukkauksia</a>;</li>
<li>Useita kauhistuttavia <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-against-its-employees-of-color-fbbfaf55ab76" target="_blank">tarinoita rasismista ja kiihkoilusta Facebookin työntekijöiden keskuudessa</a> on raportoitu nimettömästi.</li>
</ul>
<p>Tällaiset esimerkit jättävät runsaasti tilaa ihmetellä, kuinka vilpittömästi Facebook suhtautuu alkukantaiseen epäsuhtaan - ja miettiä, onko anteeksipyyntö pelkkä PR-teko, jolla pyritään estämään lisäkohua.</p>
<h2>Mitä voimme tehdä asialle?</h2>
<p>Kuvantunnistus on erittäin hyödyllinen väline, joka voi auttaa meitä parantamaan jokapäiväistä elämäämme, mutta innovaation ei saa liittyä syrjintään tai kiihkoilun vahvistamiseen. Ihmisen luokitteleminen apinaksi on niin nöyryyttävää, ja on vain selvää, että Facebookia yrityksenä pitäisi pitää vastuullisena.</p>
<p>On vain triviaalia, että yksinkertainen algoritmi voi johtaa suuriin seurauksiin suurella alustalla, ja siksi algoritmeja pitäisi käsitellä niin. Kasvontunnistusalgoritmin ei pitäisi olla vain jotain, jonka voi vain heittää miljoonien ihmisten päälle, ja tuhansien ihmisten luokitteleminen gorillaosastoon on yhtä tuomittavaa kuin näiden ihmisten tuomitseminen julkisesti apinoiksi.</p>
<p>Anteeksipyyntö ei saa riittää, varsinkaan yritykselle, jolla on tällainen rasistinen väärinkäytösrekisteri.</p>
</article>
</section>
<footer>
<p>Tämän verkkosivuston on rakentanut <a href="https://noordstar.me/">BramvdnHeuvel</a>. <br/> Voit ottaa heihin yhteyttä <a href="mailto:digital-rights@bram.blmgroep.nl">sähköpostitse</a> tai <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
