<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά</title>
<meta content="Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά" name="title"/>
<meta content="Ποτέ δεν μπορεί κανείς να εγγυηθεί ότι μια Τεχνητή Νοημοσύνη θα παραδώσει κάποιες τρομερές παρενέργειες, αλλά το ιστορικό φυλετικής κακοποίησης του Facebook καθιστά πιθανό ότι αυτό το λάθος δεν θα είναι το τελευταίο τους." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά" property="og:title"/>
<meta content="Ποτέ δεν μπορεί κανείς να εγγυηθεί ότι μια Τεχνητή Νοημοσύνη θα παραδώσει κάποιες τρομερές παρενέργειες, αλλά το ιστορικό φυλετικής κακοποίησης του Facebook καθιστά πιθανό ότι αυτό το λάθος δεν θα είναι το τελευταίο τους." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά" property="twitter:title"/>
<meta content="Ποτέ δεν μπορεί κανείς να εγγυηθεί ότι μια Τεχνητή Νοημοσύνη θα παραδώσει κάποιες τρομερές παρενέργειες, αλλά το ιστορικό φυλετικής κακοποίησης του Facebook καθιστά πιθανό ότι αυτό το λάθος δεν θα είναι το τελευταίο τους." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Αρχική σελίδα</a>
<a href="../rights.html">Ψηφιακά δικαιώματα</a>
<a href="index.html">Άρθρα</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<section class="simple-orange">
<article class="essay-title">
<h1>Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά</h1>
<p>Αυτό είναι ένα αυθεντικό άρθρο που γράφτηκε από τον <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Εκτιμώμενος χρόνος ανάγνωσης: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 λεπτά.</p>
</article>
</section>
<section class="simple-gray flex-container">
<article class="blog">
<h1>Το Facebook ζητά συγγνώμη για την ταξινόμηση των μαύρων ανδρών ως πρωτεύοντα θηλαστικά</h1>
<p>Οι τεχνητές νοημοσύνες μπορεί να έχουν φυλετικές προκαταλήψεις. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Τα καυκάσια πρόσωπα έχουν 10 έως 100 φορές περισσότερες πιθανότητες να αναγνωριστούν και να ταυτοποιηθούν σωστά</a> από ό,τι τα αφροαμερικανικά και τα ασιατικά πρόσωπα, γεγονός που έχει ήδη οδηγήσει σε <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">άδικες κατηγορίες, συλλήψεις, ακόμη και φυλακίσεις</a> επειδή μια τεχνητή νοημοσύνη δεν μπόρεσε να αντιστοιχίσει σωστά ένα μη λευκό πρόσωπο.</p>
<p>Πολλοί μαθητές το βίωσαν αυτό από πρώτο χέρι κατά τη διάρκεια της πανδημίας. Πολλές εταιρείες όπως η <a href="https://proctorio.com/" target="_blank">Proctorio</a> έχουν σημειώσει μεγάλες επιτυχίες σε πανεπιστήμια και σχολεία, όπου οι καθηγητές καθοδηγούν τους μαθητές τους να εγκαταστήσουν λογισμικό που ελέγχει αν κάνουν ένα τεστ με ειλικρίνεια. Το λογισμικό ήταν πιο πιθανό να κατηγορήσει τους έγχρωμους για αντιγραφή, επειδή <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">το λογισμικό δεν μπορούσε να αναγνωρίσει τα πρόσωπά τους</a>. Τέτοια λογισμικά ελέγχου έχει αποδειχθεί ότι <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">ενισχύουν τη λευκή υπεροχή, τον σεξισμό, τον ableism και την τρανσφοβία</a>.</p>
<h2>Το λάθος του Facebook</h2>
<p>Η συγγνώμη του Facebook αφορούσε μαύρους άνδρες σε συμπλοκές με λευκούς πολίτες και αστυνομικούς, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">σύμφωνα με τους New York Times</a>. Μια τεχνητή νοημοσύνη αναγνώρισης εικόνας ταξινόμησε τα κλιπ ως πλάνα από μαϊμούδες ή πρωτεύοντα θηλαστικά, παρόλο που τα βίντεο δεν είχαν καμία σχέση με κανένα από τα δύο.</p>
<p>Πώς συμβαίνει αυτό; Η προκατάληψη σε μια τεχνητή νοημοσύνη είναι συνήθως αποτέλεσμα ενός προκατειλημμένου συνόλου εκπαίδευσης. Όπως εξηγεί η Joy Buolamwini στην <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">ομιλία της στο TED</a>, όπου εξηγεί πώς το λογισμικό αναγνώρισης προσώπου δεν μπόρεσε να αναγνωρίσει το πρόσωπό της. Με τον ίδιο τρόπο, ένα σύνολο δεδομένων <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">όπου πάνω από το 80% των προσώπων είναι λευκά</a> μπορεί να δυσκολευτεί περισσότερο να αναγνωρίσει ανθρώπους με διαφορετικό χρώμα δέρματος και να καταφύγει στην ταξινόμηση αυτών των προσώπων ως κάτι που μοιάζει με άνθρωπο - όπως οι πίθηκοι και άλλα πρωτεύοντα θηλαστικά.</p>
<p>Ένα παρόμοιο σκάνδαλο με το πρόσφατο λάθος του Facebook παρατηρήθηκε το 2015, όταν η Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">ταυτοποίησε λανθασμένα μαύρους ανθρώπους ως γορίλες στις φωτογραφίες Google</a>. Ωστόσο, αντί να αλλάξει την τεχνητή νοημοσύνη, η <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos ξεφορτώθηκε λέξεις όπως "γορίλας", "χιμπατζής", "χιμπατζής" και "μαϊμού". Αν και αυτό σημαίνει ότι οι άνθρωποι δεν θα αναγνωρίζονται πλέον ως πίθηκοι στις φωτογραφίες Google Photos, υποδηλώνει ότι τα βασικά προβλήματα με την τεχνητή νοημοσύνη δεν έχουν διορθωθεί ακόμη.</a></p>
<h2>Η φυλετική παραβατική συμπεριφορά του Facebook</h2>
<p>Παρόλο που το λάθος της τεχνητής νοημοσύνης του Facebook προέρχεται από ένα υποκείμενο ζήτημα που παίζει σε κοινωνικό επίπεδο, το Facebook έχει ιστορικό καταχρήσεων, συχνά φυλετικών.</p>
<ul>
<li>Οι χρήστες του Instagram, των οποίων η δραστηριότητα υποδήλωνε ότι ήταν μαύροι, είχαν 50% περισσότερες πιθανότητες να απενεργοποιηθούν αυτόματα οι λογαριασμοί τους. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Οι ερευνητές ενημερώθηκαν από τους προϊσταμένους τους να σταματήσουν την έρευνα και να σιωπήσουν γι' αυτήν</a>,</li>
<li>Ο Μαρκ Ζούκερμπεργκ, διευθύνων σύμβουλος του Facebook, <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">έπρεπε να ζητήσει δημοσίως από τους υπαλλήλους να σταματήσουν να σβήνουν συνθήματα του Black Lives Matter</a>,</li>
<li>Το Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">απέτυχε να περιορίσει τη ρατσιστική κακοποίηση των ποδοσφαιριστών της Αγγλίας</a>,</li>
<li>Αρκετές τρομακτικές <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-its-employees-of-color-fbbfaf55ab76" target="_blank">ιστορίες ρατσισμού και μισαλλοδοξίας μεταξύ των υπαλλήλων του Facebook</a> έχουν αναφερθεί ανώνυμα.</li>
</ul>
<p>Παραδείγματα όπως αυτά αφήνουν πολλά περιθώρια να αναρωτηθεί κανείς πόσο ειλικρινά παίρνει το Facebook την αναντιστοιχία πρωτευόντων - και να αναρωτηθεί αν η συγγνώμη είναι απλώς μια ενέργεια δημοσίων σχέσεων για να αποφευχθεί περαιτέρω διαμάχη.</p>
<h2>Τι μπορούμε να κάνουμε γι' αυτό;</h2>
<p>Η αναγνώριση εικόνας είναι ένα πολύ χρήσιμο εργαλείο που μπορεί να μας βοηθήσει να βελτιώσουμε την καθημερινή μας ζωή, αλλά η καινοτομία δεν πρέπει να συνοδεύεται από διακρίσεις ή ενίσχυση της μισαλλοδοξίας. Η ταξινόμηση ενός ανθρώπου ως πιθήκου είναι τέτοιας ταπείνωσης και δεν είναι παρά προφανές ότι το Facebook ως εταιρεία θα πρέπει να θεωρηθεί υπεύθυνο.</p>
<p>Είναι ασήμαντο ότι ένας απλός αλγόριθμος μπορεί να οδηγήσει σε σημαντικές συνέπειες σε μια μεγάλη πλατφόρμα, και ως εκ τούτου οι αλγόριθμοι θα πρέπει να αντιμετωπίζονται με αυτόν τον τρόπο. Ένας αλγόριθμος αναγνώρισης προσώπων δεν θα έπρεπε να είναι απλώς κάτι που μπορείτε να ρίξετε σε εκατομμύρια ανθρώπους, και η κατηγοριοποίηση χιλιάδων ανθρώπων στο τμήμα των γορίλων είναι εξίσου απαράδεκτη με τη δημόσια καταγγελία αυτών των ανθρώπων ως πιθήκων.</p>
<p>Μην αφήσετε μια συγγνώμη να είναι αρκετή, ειδικά για μια εταιρεία με τέτοιο ιστορικό φυλετικών καταχρήσεων.</p>
</article>
</section>
<footer>
<p>Αυτός ο δικτυακός τόπος κατασκευάστηκε από την <a href="https://noordstar.me/">BramvdnHeuvel</a>.<br/> Μπορείτε να επικοινωνήσετε μαζί τους μέσω <a href="mailto:digital-rights@bram.blmgroep.nl">email</a> ή στο <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
