<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov</title>
<meta content="Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov" name="title"/>
<meta content="Nikdy nemožno zaručiť, že umelá inteligencia neprinesie nejaké hrozné vedľajšie účinky, ale vzhľadom na históriu rasového zneužívania spoločnosti Facebook je pravdepodobné, že táto chyba nebude ich poslednou." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov" property="og:title"/>
<meta content="Nikdy nemožno zaručiť, že umelá inteligencia neprinesie nejaké hrozné vedľajšie účinky, ale vzhľadom na históriu rasového zneužívania spoločnosti Facebook je pravdepodobné, že táto chyba nebude ich poslednou." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov" property="twitter:title"/>
<meta content="Nikdy nemožno zaručiť, že umelá inteligencia neprinesie nejaké hrozné vedľajšie účinky, ale vzhľadom na históriu rasového zneužívania spoločnosti Facebook je pravdepodobné, že táto chyba nebude ich poslednou." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Domov</a>
<a href="../rights.html">Digitálne práva</a>
<a href="index.html">Články</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov</h1>
<p>Toto je autentický článok, ktorého autorom je <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Odhadovaný čas čítania: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook sa ospravedlnil za to, že černochov klasifikoval ako primátov</h1>
<p>Umelé inteligencie môžu mať rasové predsudky. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Tváre belochov majú 10 až 100-krát vyššiu pravdepodobnosť správneho rozpoznania a identifikácie</a> ako tváre Afroameričanov a Ázijcov, čo už viedlo k <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">nesprávnym obvineniam, zatknutiam a dokonca uväzneniam</a>, pretože umelá inteligencia nedokázala správne priradiť tvár inej ako bielej farby.</p>
<p>Mnohí študenti to zažili na vlastnej koži počas pandémie. Mnohé spoločnosti ako <a href="https://proctorio.com/" target="_blank">Proctorio</a> dosiahli veľké úspechy na univerzitách a školách, kde učitelia inštruujú svojich študentov, aby si nainštalovali softvér, ktorý kontroluje, či robia test poctivo. Tento softvér častejšie obviňoval farebných ľudí z podvádzania, pretože <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">softvér nedokázal rozpoznať ich tváre</a>. Ukázalo sa, že takýto proktorovací softvér <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">posilňuje nadradenosť bielej rasy, sexizmus, ableizmus a transfóbiu</a>.</p>
<h2>Chyba spoločnosti Facebook</h2>
<p>Ospravedlnenie spoločnosti Facebook sa týkalo černochov v konfliktoch s bielymi civilistami a policajtmi, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">podľa denníka The New York Times</a>. Umelá inteligencia na rozpoznávanie obrazu klasifikovala klipy ako zábery opíc alebo primátov, hoci videá nemali nič spoločné ani s jedným z nich.</p>
<p>Ako k tomu dochádza? Predpojatosť umelej inteligencie je zvyčajne výsledkom neobjektívneho tréningového súboru. Ako vysvetľuje Joy Buolamwini v <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">svojej prednáške na TED</a>, kde vysvetľuje, ako softvér na rozpoznávanie tváre nedokázal rozpoznať jej tvár. Rovnako tak súbor údajov <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">kde je viac ako 80 percent tvárí bielych</a> môže mať ťažšie rozpoznávanie ľudí s inou farbou pleti a môže sa uchýliť k klasifikácii týchto tvárí ako niečoho blízkeho človeku - napríklad opíc a iných primátov.</p>
<p>Podobný škandál ako nedávna chyba Facebooku sa odohral v roku 2015, keď spoločnosť Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">na fotografiách Google omylom identifikovala černochov ako gorily</a>. Namiesto zmeny umelej inteligencie sa však <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos zbavil slov ako "gorila", "šimpanz", "šimpanz" a "opica". Hoci to znamená, že ľudia už nebudú na Fotkách Google identifikovaní ako opice, naznačuje to, že základné problémy s umelou inteligenciou ešte neboli odstránené.</a></p>
<h2>Rasové pochybenie spoločnosti Facebook</h2>
<p>Hoci chyba umelej inteligencie Facebooku vychádza zo základného problému, ktorý sa odohráva na spoločenskej úrovni, Facebook má na svojom konte zneužívanie, často rasové.</p>
<ul>
<li>Používatelia Instagramu, ktorých aktivita naznačovala, že sú čiernej pleti, mali o 50 % vyššiu pravdepodobnosť, že ich účty budú automaticky deaktivované. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Vedcom ich nadriadení povedali, aby výskum zastavili a mlčali o ňom</a>;</li>
<li>Mark Zuckerberg, generálny riaditeľ Facebooku, <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">musel verejne požiadať zamestnancov, aby prestali preškrtávať slogany Black Lives Matter</a>;</li>
<li>Spoločnosť Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">zlyhala pri zastavení rasistických nadávok na anglických futbalistov</a>;</li>
<li>Anonymne bolo nahlásených niekoľko desivých <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-againstits-employees-of-color-fbbfaf55ab76" target="_blank">príbehov o rasizme a bigotnosti medzi zamestnancami Facebooku</a>.</li>
</ul>
<p>Príklady, ako sú tieto, ponechávajú dostatok priestoru na zamyslenie sa nad tým, ako úprimne berie Facebook primárne nezhodu - a na zamyslenie sa nad tým, či je ospravedlnenie len PR akciou, ktorá má zabrániť ďalším kontroverziám.</p>
<h2>Čo s tým môžeme urobiť?</h2>
<p>Rozpoznávanie obrazov je veľmi užitočný nástroj, ktorý nám môže pomôcť zlepšiť náš každodenný život, ale inovácie nesmú byť spojené s diskrimináciou alebo posilňovaním bigotnosti. Klasifikácia človeka ako opice je takouto nedôstojnosťou a nie je ničím iným ako samozrejmosťou, že Facebook ako spoločnosť by mal niesť zodpovednosť.</p>
<p>Je len triviálne, že jednoduchý algoritmus môže viesť k závažným dôsledkom na veľkej platforme, a preto by sa k algoritmom malo takto pristupovať. Algoritmus na rozpoznávanie tvárí by nemal byť jednoducho niečo, čo môžete len tak hodiť na milióny ľudí, a zaradenie tisícov ľudí do sekcie goríl je rovnako neprijateľné ako verejné odsúdenie týchto ľudí ako opíc.</p>
<p>Nech ospravedlnenie nestačí, najmä v prípade spoločnosti s takou históriou rasového zneužívania.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Túto webovú stránku založil <a href="https://noordstar.me/">BramvdnHeuvel</a>. Tu je <a href="https://github.com/BramvdnHeuvel/Digital-Justice">zdrojový kód.</a><br/> Môžete ich kontaktovať na <a href="mailto:hello@digital-justice.com">email</a> alebo na <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
