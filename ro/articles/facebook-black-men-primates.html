<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate</title>
<meta content="Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate" name="title"/>
<meta content="Nu se poate garanta niciodată că o inteligență artificială oferă niște efecte secundare îngrozitoare, dar istoricul de abuzuri rasiale al Facebook face probabil ca această greșeală să nu fie ultima." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate" property="og:title"/>
<meta content="Nu se poate garanta niciodată că o inteligență artificială oferă niște efecte secundare îngrozitoare, dar istoricul de abuzuri rasiale al Facebook face probabil ca această greșeală să nu fie ultima." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate" property="twitter:title"/>
<meta content="Nu se poate garanta niciodată că o inteligență artificială oferă niște efecte secundare îngrozitoare, dar istoricul de abuzuri rasiale al Facebook face probabil ca această greșeală să nu fie ultima." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Acasă</a>
<a href="../rights.html">Drepturile digitale</a>
<a href="index.html">Articole</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate</h1>
<p>Acesta este un articol autentic scris de <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Timp estimat de lectură: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 minute.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook își cere scuze pentru că a clasificat bărbații de culoare drept primate</h1>
<p>Inteligențele artificiale pot avea prejudecăți rasiale. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Facele caucaziene au de 10 până la 100 de ori mai multe șanse de a fi recunoscute și identificate corect</a> decât fețele afro-americane și asiatice, ceea ce a dus deja la <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">acuzații greșite, arestări și chiar încarcerări</a> pentru că o inteligență artificială nu a putut potrivi corect o față care nu era albă.</p>
<p>Mulți studenți au experimentat acest lucru pe propria piele în timpul pandemiei. Multe companii precum <a href="https://proctorio.com/" target="_blank">Proctorio</a> au înregistrat mari succese în universități și școli, unde profesorii își instruiesc studenții să instaleze un software care verifică dacă fac un test în mod onest. Software-ul a fost mai probabil să acuze persoanele de culoare de trișat, deoarece <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">protocolul nu le putea recunoaște fețele</a>. Astfel de software de supraveghere s-a dovedit a <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">reforța supremația albilor, sexismul, ableismul și transfobia</a>.</p>
<h2>Greșeala Facebook</h2>
<p>Scuzele prezentate de Facebook au vizat bărbați de culoare în altercații cu civili albi și polițiști, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">conform The New York Times</a>. O inteligență artificială de recunoaștere a imaginilor a clasificat clipurile ca fiind imagini cu maimuțe sau primate, chiar dacă videoclipurile nu aveau nicio legătură cu niciuna dintre acestea.</p>
<p>Cum se poate întâmpla acest lucru? O prejudecată într-o inteligență artificială este, de obicei, rezultatul unui set de antrenament părtinitor. După cum explică Joy Buolamwini în <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">vorbirea ei TED</a>, în care explică cum un software de recunoaștere a feței nu i-a putut recunoaște fața. La fel, un set de date <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">în care peste 80 la sută dintre fețe sunt albe</a> ar putea recunoaște mai greu persoanele cu piele de culori diferite și ar putea recurge la clasificarea fețelor respective ca fiind ceva apropiat de un om - cum ar fi maimuțele și alte primate.</p>
<p>Un scandal similar cu recenta greșeală a Facebook a fost văzut în 2015, când Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">a identificat în mod eronat persoane de culoare ca fiind gorile în Google Photos</a>. Cu toate acestea, în loc să schimbe inteligența artificială, <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos a scăpat de cuvinte precum "gorilă", "cimpanzeu", "cimpanzeu" și "maimuță". Deși acest lucru înseamnă că oamenii nu vor mai fi identificați ca maimuțe pe Google Photos, sugerează că problemele de bază ale inteligenței artificiale nu au fost încă rezolvate.</a>.</p>
<h2>Comportamentul rasist al Facebook</h2>
<p>Deși greșeala AI-ului de la Facebook provine dintr-o problemă de fond care joacă la nivel societal, Facebook are un istoric de abuzuri, adesea rasiale.</p>
<ul>
<li>Utilizatorii Instagram a căror activitate sugera că sunt de culoare au avut cu 50% mai multe șanse să le fie dezactivate automat conturile. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Cercetătorii au fost sfătuiți de superiorii lor să oprească cercetarea și să păstreze tăcerea în legătură cu aceasta</a>;</li>
<li>Mark Zuckerberg, directorul general al Facebook, <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">a trebuit să le ceară public angajaților să nu mai taie sloganurile Black Lives Matter</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">a eșuat în încercarea de a opri abuzurile rasiste la adresa jucătorilor de fotbal din Anglia</a>;</li>
<li>Mai multe <a href="https://medium.com/@blindfb202020/facebook-empowers-racism-against-its-employees-of-color-fbbfaf55ab76" target="_blank">povești îngrozitoare de rasism și intoleranță în rândul angajaților Facebook</a> au fost raportate în mod anonim.</li>
</ul>
<p>Exemple ca acestea lasă loc de multe semne de întrebare cu privire la cât de sincer ia Facebook în considerare nepotrivirea primelor - și să ne întrebăm dacă scuzele sunt doar o acțiune de PR pentru a preveni alte controverse.</p>
<h2>Ce putem face în această privință?</h2>
<p>Recunoașterea imaginilor este un instrument foarte util care ne poate ajuta să ne îmbunătățim viața de zi cu zi, dar inovația nu trebuie să vină la pachet cu discriminarea sau consolidarea intoleranței. Clasificarea unui om ca fiind o maimuță este de o asemenea indignare și nu este nimic altceva decât evident că Facebook, ca și companie, ar trebui să fie trasă la răspundere.</p>
<p>Este doar banal ca un algoritm simplu să poată duce la consecințe majore pe o platformă mare și, prin urmare, algoritmii ar trebui să fie tratați în acest fel. Un algoritm de recunoaștere a fețelor nu ar trebui să fie pur și simplu ceva ce poți arunca asupra a milioane de oameni, iar clasificarea a mii de oameni în secțiunea gorilelor este la fel de inacceptabilă ca și denunțarea publică a acelor oameni drept maimuțe.</p>
<p>Nu lăsați ca scuzele să fie suficiente, mai ales pentru o companie cu un asemenea istoric de abuzuri rasiale.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Acest site a fost fondat de <a href="https://noordstar.me/">BramvdnHeuvel</a>. Aici este <a href="https://github.com/BramvdnHeuvel/Digital-Justice">codul sursă.</a><br/> Îi puteți contacta prin <a href="mailto:digital-rights@bram.blmgroep.nl">email</a> sau pe <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
