<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem</title>
<meta content="Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem" name="title"/>
<meta content="Nekad nevar garantēt, ka mākslīgais intelekts nenodrošinās kādu briesmīgu blakusefektu, taču Facebook rasu ļaunprātīgas izmantošanas vēsture liek domāt, ka šī kļūda nebūs viņu pēdējā." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem" property="og:title"/>
<meta content="Nekad nevar garantēt, ka mākslīgais intelekts nenodrošinās kādu briesmīgu blakusefektu, taču Facebook rasu ļaunprātīgas izmantošanas vēsture liek domāt, ka šī kļūda nebūs viņu pēdējā." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem" property="twitter:title"/>
<meta content="Nekad nevar garantēt, ka mākslīgais intelekts nenodrošinās kādu briesmīgu blakusefektu, taču Facebook rasu ļaunprātīgas izmantošanas vēsture liek domāt, ka šī kļūda nebūs viņu pēdējā." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Sākums</a>
<a href="../rights.html">Digitālās tiesības</a>
<a href="index.html">Raksti</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem</h1>
<p>Šis ir autentisks <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a> raksts.</p>
<p>Paredzamais lasīšanas laiks: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook atvainojas par melnādaino vīriešu klasificēšanu par primātiem</h1>
<p>Mākslīgajam intelektam var būt rasu aizspriedumi. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Kaukazas sejas 10 līdz 100 reižu biežāk tiek pareizi atpazītas un identificētas</a> nekā afroamerikāņu vai aziātu sejas, kas jau ir novedis pie <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">nelikumīgām apsūdzībām, arestiem un pat apcietinājumiem</a>, jo mākslīgais intelekts nespēja pareizi atpazīt seju, kas nav balta.</p>
<p>Daudzi studenti to piedzīvoja uz savas ādas pandēmijas laikā. Daudzi uzņēmumi, piemēram, <a href="https://proctorio.com/" target="_blank">Proctorio</a>, ir guvuši lielus panākumus universitātēs un skolās, kur skolotāji uzdod skolēniem instalēt programmatūru, kas pārbauda, vai viņi godīgi kārto testu. Šī programmatūra biežāk vainoja krāpšanā krāsainus cilvēkus, jo <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">programmatūra nespēja atpazīt viņu sejas</a>. Ir pierādīts, ka šāda proktoru programmatūra <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">pastiprina baltās rases pārākumu, seksismu, spējismu un transfobiju</a>.</p>
<h2>Facebook kļūda</h2>
<p>Facebook atvainošanās attiecās uz melnādainiem vīriešiem, kas iesaistīti konfliktos ar baltajiem civiliedzīvotājiem un policistiem, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">paskaidroja The New York Times</a>. Attēlu atpazīšanas mākslīgais intelekts klasificēja klipus kā pērtiķu vai primātu kadrus, lai gan videoklipiem nebija nekāda sakara ne ar vienu, ne ar otru.</p>
<p>Kā tas notiek? Mākslīgā intelekta neobjektivitāte parasti rodas neobjektīvas mācību kopas rezultātā. Kā skaidro Džoija Buolamvini (Joy Buolamwini) <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">savā TED lekcijā</a>, kurā viņa skaidro, kā sejas atpazīšanas programmatūra nespēja atpazīt viņas seju. Tāpat datu kopai <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">kur vairāk nekā 80 procenti seju ir baltādainas</a>, var būt grūtāk atpazīt dažādu ādas krāsu cilvēkus, un tā var ķerties pie šo seju klasificēšanas kā kaut ko tuvu cilvēkam - piemēram, pērtiķus un citus primātus.</p>
<p>Līdzīgs skandāls kā Facebook nesen pieļautā kļūda bija vērojams 2015. gadā, kad Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">kļūdaini identificēja melnādainus cilvēkus kā gorillas Google Photos</a>. Tomēr tā vietā, lai mainītu mākslīgo intelektu, <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos atbrīvojās no tādiem vārdiem kā "gorilla", "chimp", "chimpanzee" un "monkey". Lai gan tas nozīmē, ka cilvēki Google Photos vairs netiks identificēti kā pērtiķi, tas liecina, ka mākslīgā intelekta pamatproblēmas vēl nav novērstas.</a>.</p>
<h2>Facebook pārkāpumi rasu dēļ</h2>
<p>Lai gan Facebook mākslīgā intelekta kļūda ir saistīta ar pamatjautājumu, kas darbojas sabiedrības līmenī, Facebook ir reģistrēti pārkāpumi, bieži vien rasistiski.</p>
<ul>
<li>Instagram lietotājiem, kuru aktivitātes liecināja par to, ka viņi ir melnādainie, bija par 50 % lielāka iespēja, ka viņu konti tiks automātiski atspējoti. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Izpētniekiem viņu priekšnieki lika pārtraukt pētījumu un par to klusēt</a>;</li>
<li>Facebook izpilddirektors Marks Cukerbergs <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">bija publiski lūdzis darbiniekus pārtraukt svītrot "Black Lives Matter" saukļus</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">neizdevās apturēt rasistisku Anglijas futbolistu apvainojumus</a>;</li>
<li>Anonīmi ir ziņots par vairākiem šausminošiem <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-againstits-gaism-gaism-againstits-employees-of-color-fbbfaf55ab76" target="_blank">stāstiem par rasismu un fanātismu Facebook darbinieku vidū</a>.</li>
</ul>
<p>Šādi piemēri atstāj daudz vietas, lai aizdomātos, cik sirsnīgi Facebook uztver primātu neatbilstību - un vai atvainošanās nav vienkārši PR akcija, lai novērstu turpmākas diskusijas.</p>
<h2>Ko mēs varam darīt?</h2>
<p>Attēlu atpazīšana ir ļoti noderīgs rīks, kas var palīdzēt mums uzlabot mūsu ikdienas dzīvi, taču inovācijas nedrīkst būt saistītas ar diskrimināciju vai fanātisma pastiprināšanu. Cilvēka klasificēšana par pērtiķi ir tik pazemojoša, un nav nekas cits kā acīmredzams, ka Facebook kā uzņēmumam būtu jāuzņemas atbildība.</p>
<p>Tas ir tikai triviāli, ka vienkāršs algoritms var radīt nopietnas sekas lielā platformā, un tāpēc pret algoritmiem ir jāizturas šādi. Sejas atpazīšanas algoritmam nevajadzētu būt vienkārši kaut kam, ko var vienkārši uzmest miljoniem cilvēku, un tūkstošiem cilvēku iedalīšana gorillu sadaļā ir tikpat nepieņemama kā šo cilvēku publiska nosodīšana par pērtiķiem.</p>
<p>Lai ar atvainošanos nepietiktu, jo īpaši uzņēmumam, kam ir šāda rasu pārkāpumu vēsture.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Šo tīmekļa vietni izveidoja <a href="https://noordstar.me/">BramvdnHeuvel</a>. Šeit ir <a href="https://github.com/BramvdnHeuvel/Digital-Justice">izcelsmes kods.</a><br/>Ar viņu var sazināties pa <a href="mailto:hello@digital-justice.com">pastu</a> vai pa <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matricu</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
