<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook se je opravičil, ker je črnce uvrstil med primate</title>
<meta content="Facebook se je opravičil, ker je črnce uvrstil med primate" name="title"/>
<meta content="Nikoli ne moremo zagotoviti, da umetna inteligenca ne prinese kakšnih grozljivih stranskih učinkov, vendar je zaradi Facebookove zgodovine rasnih zlorab verjetno, da ta napaka ne bo njihova zadnja." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook se je opravičil, ker je črnce uvrstil med primate" property="og:title"/>
<meta content="Nikoli ne moremo zagotoviti, da umetna inteligenca ne prinese kakšnih grozljivih stranskih učinkov, vendar je zaradi Facebookove zgodovine rasnih zlorab verjetno, da ta napaka ne bo njihova zadnja." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook se je opravičil, ker je črnce uvrstil med primate" property="twitter:title"/>
<meta content="Nikoli ne moremo zagotoviti, da umetna inteligenca ne prinese kakšnih grozljivih stranskih učinkov, vendar je zaradi Facebookove zgodovine rasnih zlorab verjetno, da ta napaka ne bo njihova zadnja." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Domov</a>
<a href="../rights.html">Digitalne pravice</a>
<a href="index.html">Članki</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<section class="simple-orange">
<article class="essay-title">
<h1>Facebook se je opravičil, ker je črnce uvrstil med primate</h1>
<p>To je verodostojen članek, ki ga je napisal <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Predviden čas branja: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section class="simple-gray flex-container">
<article class="blog">
<h1>Facebook se je opravičil, ker je črnce uvrstil med primate</h1>
<p>Umetne inteligence imajo lahko rasne predsodke. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Pravilno prepoznavanje in identifikacija kavkaških obrazov je 10 do 100-krat bolj verjetna</a> kot afroameriških in azijskih, kar je že pripeljalo do <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">nepravilnih obtožb, aretacij in celo zapornih kazni</a>, ker umetna inteligenca ni mogla pravilno primerjati obraza, ki ni belca.</p>
<p>Veliko študentov je to izkusilo na lastni koži med pandemijo. Številna podjetja, kot je <a href="https://proctorio.com/" target="_blank">Proctorio</a>, so dosegla velike uspehe na univerzah in šolah, kjer učitelji učencem naročijo, naj namestijo programsko opremo, ki preveri, ali so test naredili pošteno. Ta programska oprema je bolj verjetno obtoževala barvne ljudi goljufanja, ker <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">programska oprema ni mogla prepoznati njihovih obrazov</a>. Pokazalo se je, da takšna programska oprema za preverjanje znanja <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">pospešuje nadvlado belcev, seksizem, ableizem in transfobijo</a>.</p>
<h2>Facebookova napaka</h2>
<p>Facebookovo opravičilo se je nanašalo na temnopolte moške v spopadih z belimi civilisti in policisti, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">po navedbah časopisa The New York Times</a>. Umetna inteligenca za prepoznavanje slik je posnetke razvrstila kot posnetke opic ali primatov, čeprav videoposnetki niso imeli nič skupnega z nobenim od teh.</p>
<p>Kako se to zgodi? Predsodek v umetni inteligenci je običajno posledica pristranskega nabora za usposabljanje. Kot je razložila Joy Buolamwini v <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">predavanju na TED</a>, kjer je pojasnila, kako programska oprema za prepoznavanje obrazov ni mogla prepoznati njenega obraza. Na enak način lahko nabor podatkov <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">kjer je več kot 80 odstotkov obrazov belih</a> težje prepozna ljudi različnih barv kože in se lahko zateče k razvrščanju teh obrazov kot nečesa, kar je blizu človeku - kot so opice in drugi primati.</p>
<p>Podoben škandal kot nedavna Facebookova napaka se je zgodil leta 2015, ko je Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">v Google Photos</a> po pomoti označil črnce kot gorile. Vendar pa se je <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos namesto spremembe umetne inteligence znebil besed, kot so "gorila", "šimpanz", "šimpanz" in "opica". Čeprav to pomeni, da ljudje na Google Photos ne bodo več prepoznani kot opice, to nakazuje, da osnovne težave z umetno inteligenco še niso bile odpravljene.</a></p>
<h2>Facebookova rasna zloraba</h2>
<p>Čeprav napaka Facebookove umetne inteligence izhaja iz temeljnega vprašanja, ki se odvija na družbeni ravni, ima Facebook v svoji zgodovini tudi zlorabe, pogosto rasne.</p>
<ul>
<li>Pri uporabnikih Instagrama, katerih dejavnost je nakazovala, da so temnopolti, je bilo 50 % več možnosti, da bodo njihovi računi samodejno onemogočeni. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Nadrejeni so raziskovalcem rekli, naj ustavijo raziskavo in o njej molčijo</a>;</li>
<li>Mark Zuckerberg, izvršni direktor Facebooka, je <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">zaposlene javno pozval, naj nehajo prečrtavati slogane Black Lives Matter</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">neuspešno ustavil rasistično zlorabo angleških nogometašev</a>;</li>
<li>Več grozljivih <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-its-employees-of-color-fbbfaf55ab76" target="_blank">pripovedi o rasizmu in fanatizmu med Facebookovimi zaposlenimi</a> je bilo prijavljenih anonimno.</li>
</ul>
<p>Takšni primeri puščajo veliko prostora za spraševanje, kako iskreno Facebook jemlje neprimerjanje primatov - in za spraševanje, ali je opravičilo zgolj PR akcija za preprečevanje nadaljnjih polemik.</p>
<h2>Kaj lahko storimo glede tega?</h2>
<p>Prepoznavanje podob je zelo uporabno orodje, ki nam lahko pomaga izboljšati naše vsakdanje življenje, vendar inovacije ne smejo biti povezane z diskriminacijo ali krepitvijo fanatizma. Razvrstitev človeka v opico je tako ponižujoča in ni nič drugega kot očitno, da bi moral biti Facebook kot podjetje za to odgovoren.</p>
<p>Trivialno je, da lahko preprost algoritem privede do velikih posledic na veliki platformi, zato je treba algoritme obravnavati na tak način. Algoritem za prepoznavanje obrazov ne bi smel biti preprosto nekaj, kar lahko preprosto vržete na milijone ljudi, in razvrščanje tisočih ljudi v oddelek goril je enako nesprejemljivo kot javna obsodba teh ljudi kot opic.</p>
<p>Naj opravičilo ne bo dovolj, še posebej ne za podjetje, ki je bilo tako pogosto žrtev rasnih zlorab.</p>
</article>
</section>
<footer>
<p>To spletno stran je zgradil <a href="https://noordstar.me/">BramvdnHeuvel</a>.<br/> Lahko jih kontaktirate preko <a href="mailto:digital-rights@bram.blmgroep.nl">pošte</a> ali na <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
