<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks</title>
<meta content="Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks" name="title"/>
<meta content="Kunagi ei saa garanteerida, et tehisintellektuaali puhul ei teki mingeid kohutavaid kõrvalmõjusid, kuid Facebooki rassilise väärkohtlemise ajalugu muudab tõenäoliseks, et see viga ei jää nende viimaseks." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks" property="og:title"/>
<meta content="Kunagi ei saa garanteerida, et tehisintellektuaali puhul ei teki mingeid kohutavaid kõrvalmõjusid, kuid Facebooki rassilise väärkohtlemise ajalugu muudab tõenäoliseks, et see viga ei jää nende viimaseks." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks" property="twitter:title"/>
<meta content="Kunagi ei saa garanteerida, et tehisintellektuaali puhul ei teki mingeid kohutavaid kõrvalmõjusid, kuid Facebooki rassilise väärkohtlemise ajalugu muudab tõenäoliseks, et see viga ei jää nende viimaseks." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Kodu</a>
<a href="../rights.html">Digitaalsed õigused</a>
<a href="index.html">Artiklid</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks</h1>
<p>See on autentne artikkel, mille on kirjutanud <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Hinnanguline lugemisaeg: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook vabandab, et klassifitseeris mustanahalisi mehi primaatideks</h1>
<p>Tehisintellektidel võivad olla rassilised eelarvamused. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">kaukaaslaste näod on 10 kuni 100 korda tõenäolisemalt õigesti äratuntavad ja tuvastatavad</a> kui afroameeriklaste ja aasialaste näod, mis on juba viinud <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">vale süüdistuste, vahistamiste ja isegi vangistamiste</a> juurde, sest tehisintellekt ei suutnud mittevalget nägu õigesti tuvastada.</p>
<p>Paljud üliõpilased on seda pandeemia ajal omal nahal kogenud. Paljud ettevõtted nagu <a href="https://proctorio.com/" target="_blank">Proctorio</a> on teinud suuri edusamme ülikoolides ja koolides, kus õpetajad juhendavad oma õpilasi paigaldama tarkvara, mis kontrollib, kas nad teevad testi ausalt. Tarkvara süüdistas pigem värvilisi inimesi petmises, sest <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">tarkvara ei suutnud nende nägusid ära tunda</a>. On ilmnenud, et selline kontrollitarkvara tugevdab <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">valge ülemvõimu, seksismi, võimetekohasust ja transfoobiat</a>.</p>
<h2>Facebooki viga</h2>
<p>Facebooki vabandus puudutas mustanahalisi mehi, kes olid kakluses valgete tsiviilisikute ja politseiametnikega, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">tema New York Times</a> kohaselt. Pildituvastuse tehisintellekt liigitas klipid ahvide või primaatide ülesvõteteks, kuigi videodel polnud midagi pistmist kumbagi.</p>
<p>Kuidas see juhtub? Tehisintellekti kallutatus on tavaliselt kallutatud treeningkogumi tulemus. Nagu Joy Buolamwini selgitab <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">selles TED-ettekandes</a>, kus ta selgitab, kuidas näotuvastustarkvara ei suutnud tema nägu ära tunda. Samamoodi võib andmekogumil <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">, kus üle 80 protsendi nägudest on valged</a>, olla raskem ära tunda eri nahavärviga inimesi ja ta võib pöörduda selle näo klassifitseerimise poole, mis on lähedane inimesele - nagu ahvid ja muud primaadid.</p>
<p>Facebooki hiljutise veaga sarnane skandaal leidis aset 2015. aastal, kui Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">tuvastas Google Fotodel</a> ekslikult mustanahalisi inimesi gorilladena. Kuid selle asemel, et muuta tehisintellekti, sai <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos lahti sellistest sõnadest nagu "gorilla", "šimpans", "šimpans" ja "ahv". Kuigi see tähendab, et inimesi ei tuvastata Google Photos'is enam ahvidena, viitab see sellele, et tehisintellekti põhiprobleemid ei ole veel kõrvaldatud.</a></p>
<h2>Facebooki rassistlik väärkäitumine</h2>
<p>Kuigi Facebooki tehisintellekti viga tuleneb ühiskondlikul tasandil mängivast põhiprobleemist, on Facebooki puhul tegemist kuritarvitustega, mis on sageli rassistlikud.</p>
<ul>
<li>Instagrami kasutajatel, kelle tegevus viitas sellele, et nad on mustanahalised, oli 50% suurem tõenäosus, et nende kontod automaatselt keelatakse. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Esimesed käskisid oma ülemustel uuringut lõpetada ja sellest vaikida</a>;</li>
<li>Facebooki tegevjuht Mark Zuckerberg <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">peatus avalikult paluma töötajatel lõpetada Black Lives Matteri loosungite üle kriipsutamine</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">ei suutnud peatada Inglismaa jalgpallurite rassistlikke solvanguid</a>;</li>
<li>Anonüümselt on teatatud mitmetest kohutavatest <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-it-employees-of-color-fbbfaf55ab76" target="_blank">lugudest rassismi ja fanatismi kohta Facebooki töötajate seas</a>.</li>
</ul>
<p>Sellised näited jätavad rohkesti ruumi imestada, kui siiralt Facebook võtab ürgorgaanilist valesti sobitamist -- ja küsida, kas vabandamine on lihtsalt PR-meede, et vältida edasisi vastuolusid.</p>
<h2>Mida me saame selle vastu ette võtta?</h2>
<p>Pildituvastus on väga kasulik vahend, mis võib aidata meil oma igapäevaelu parandada, kuid innovatsioon ei tohi kaasneda diskrimineerimisega ega fanatismi tugevdamisega. Inimese klassifitseerimine ahviks on selline alandamine ja on vaid ilmselge, et Facebook kui ettevõte peaks vastutama.</p>
<p>See on ainult triviaalne, et lihtne algoritm võib viia suurel platvormil suurte tagajärgedeni, ja seega tuleks algoritme nii käsitleda. Näotuvastuse algoritm ei tohiks olla lihtsalt midagi, mida võib lihtsalt miljonite inimeste peale visata, ja tuhandete inimeste liigitamine gorillade sektsiooni on sama vastuvõetamatu kui nende inimeste avalik hukkamõistmine ahvidena.</p>
<p>Vabandamisest ei piisa, eriti kui tegemist on ettevõttega, millel on selline rassistlik väärkohtlemine.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Selle veebisaidi asutas <a href="https://noordstar.me/">BramvdnHeuvel</a>. Siin on <a href="https://github.com/BramvdnHeuvel/Digital-Justice">lähtekood.</a><br/>Seda saate võtta ühendust <a href="mailto:digital-rights@bram.blmgroep.nl">Email</a> või <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matrix</a> kaudu.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
