<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten</title>
<meta content="Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten" name="title"/>
<meta content="Man kann nie ausschließen, dass eine künstliche Intelligenz schreckliche Nebenwirkungen hat, aber Facebooks Geschichte des rassistischen Missbrauchs macht es wahrscheinlich, dass dieser Fehler nicht der letzte sein wird." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten" property="og:title"/>
<meta content="Man kann nie ausschließen, dass eine künstliche Intelligenz schreckliche Nebenwirkungen hat, aber Facebooks Geschichte des rassistischen Missbrauchs macht es wahrscheinlich, dass dieser Fehler nicht der letzte sein wird." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten" property="twitter:title"/>
<meta content="Man kann nie ausschließen, dass eine künstliche Intelligenz schreckliche Nebenwirkungen hat, aber Facebooks Geschichte des rassistischen Missbrauchs macht es wahrscheinlich, dass dieser Fehler nicht der letzte sein wird." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Home</a>
<a href="../rights.html">Digitale Rechte</a>
<a href="index.html">Artikel</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten</h1>
<p>Dies ist ein authentischer Artikel, geschrieben von <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Geschätzte Lesedauer: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 min.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook entschuldigt sich für die Einstufung schwarzer Männer als Primaten</h1>
<p>Künstliche Intelligenzen können rassistische Vorurteile haben. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Kaukasische Gesichter werden 10- bis 100-mal häufiger richtig erkannt und identifiziert</a> als afroamerikanische und asiatische Gesichter, was bereits zu <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">unrechtmäßigen Anschuldigungen, Verhaftungen und sogar Inhaftierungen</a> geführt hat, weil eine künstliche Intelligenz ein nicht-weißes Gesicht nicht richtig zuordnen konnte.</p>
<p>Viele Studenten haben dies während der Pandemie am eigenen Leib erfahren. Viele Unternehmen wie <a href="https://proctorio.com/" target="_blank">Proctorio</a> haben große Erfolge an Universitäten und Schulen erzielt, wo Lehrer ihre Schüler anweisen, eine Software zu installieren, die überprüft, ob sie einen Test ehrlich machen. Die Software war eher in der Lage, Farbige des Betrugs zu beschuldigen, weil <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">die Software ihre Gesichter nicht erkennen konnte</a>. Es hat sich gezeigt, dass solche Prüfungssoftware <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">die weiße Vorherrschaft, Sexismus, Behindertenfeindlichkeit und Transphobie</a> verstärkt.</p>
<h2>Der Fehler von Facebook</h2>
<p>Facebooks Entschuldigung bezog sich auf schwarze Männer in Auseinandersetzungen mit weißen Zivilisten und Polizeibeamten, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank">laut The New York Times</a>. Eine Bilderkennungs-KI stufte die Clips als Aufnahmen von Affen oder Primaten ein, obwohl die Videos mit beidem nichts zu tun hatten.</p>
<p>Wie kann das passieren? Eine Verzerrung in einer künstlichen Intelligenz ist in der Regel das Ergebnis einer verzerrten Trainingsmenge. Wie Joy Buolamwini in <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">ihrem TED-Vortrag</a> erläutert, in dem sie erklärt, wie eine Gesichtserkennungssoftware ihr Gesicht nicht erkennen konnte. Genauso kann ein Datensatz, <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">bei dem über 80 Prozent der Gesichter weiß sind</a>, die Erkennung von Menschen mit anderer Hautfarbe erschweren und dazu führen, dass diese Gesichter als menschenähnlich eingestuft werden - wie Affen und andere Primaten.</p>
<p>Ein ähnlicher Skandal wie der jüngste Fehler von Facebook ereignete sich 2015, als Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">fälschlicherweise schwarze Menschen in Google Fotos</a> als Gorillas identifizierte. Anstatt jedoch die künstliche Intelligenz zu ändern, hat <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Fotos Wörter wie "Gorilla", "Schimpanse", "Schimpanse" und "Affe" gestrichen. Dies bedeutet zwar, dass Menschen auf Google Fotos nicht mehr als Affen identifiziert werden, deutet aber darauf hin, dass die zugrundeliegenden Probleme mit der KI noch nicht behoben sind.</a></p>
<h2>Facebooks rassistisches Fehlverhalten</h2>
<p>Obwohl der Fehler der Facebook-KI auf ein grundlegendes Problem zurückzuführen ist, das auf gesellschaftlicher Ebene spielt, ist Facebook für Missbrauch, oft aus rassistischen Gründen, bekannt.</p>
<ul>
<li>Bei Instagram-Nutzern, deren Aktivität darauf hindeutete, dass sie schwarz waren, war die Wahrscheinlichkeit, dass ihr Konto automatisch deaktiviert wurde, um 50 % höher. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Die Forscher wurden von ihren Vorgesetzten angewiesen, die Forschung zu beenden und darüber zu schweigen</a>;</li>
<li>Mark Zuckerberg, der CEO von Facebook, <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">musste seine Mitarbeiter öffentlich auffordern, keine Black-Lives-Matter-Slogans mehr durchzustreichen</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank">hat es versäumt, rassistische Beschimpfungen von Englands Fußballspielern einzudämmen</a>;</li>
<li>Mehrere erschreckende <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-its-employees-of-color-fbbfaf55ab76" target="_blank">Geschichten über Rassismus und Bigotterie unter Facebook-Mitarbeitern</a> wurden anonym gemeldet.</li>
</ul>
<p>Beispiele wie diese lassen viel Raum, um sich zu fragen, wie ernst Facebook den Primatenfehler nimmt - und sich zu fragen, ob die Entschuldigung nur eine PR-Aktion ist, um weitere Kontroversen zu vermeiden.</p>
<h2>Was können wir dagegen tun?</h2>
<p>Bilderkennung ist ein sehr nützliches Instrument, das uns helfen kann, unser tägliches Leben zu verbessern, aber Innovation darf nicht mit Diskriminierung oder der Verstärkung von Bigotterie einhergehen. Die Einstufung eines Menschen als Affe ist eine derartige Demütigung, und es ist nur allzu offensichtlich, dass Facebook als Unternehmen dafür verantwortlich gemacht werden sollte.</p>
<p>Es ist nur trivial, dass ein einfacher Algorithmus auf einer großen Plattform zu schwerwiegenden Konsequenzen führen kann, und daher sollten Algorithmen auch so behandelt werden. Ein Algorithmus zur Gesichtserkennung sollte nicht einfach auf Millionen von Menschen angewandt werden können, und Tausende von Menschen in die Gorilla-Abteilung einzuordnen, ist ebenso inakzeptabel wie diese Menschen öffentlich als Affen zu bezeichnen.</p>
<p>Eine Entschuldigung reicht nicht aus, vor allem nicht für ein Unternehmen mit einer derartigen Erfolgsbilanz bei rassistischem Missbrauch.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Diese Website wurde von <a href="https://noordstar.me/">BramvdnHeuvel</a> gegründet. Hier ist <a href="https://github.com/BramvdnHeuvel/Digital-Justice">der Quellcode.</a><br/> Sie können sie per <a href="mailto:digital-rights@bram.blmgroep.nl">E-Mail</a> oder auf <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matrix</a> kontaktieren.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
