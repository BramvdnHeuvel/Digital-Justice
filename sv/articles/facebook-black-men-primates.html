<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Open Sans font -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,200i,300,300i,400,400i,600,600i,700,700i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" id="u-theme-google-font" rel="stylesheet"/>
<!-- Playfair Display font-->
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,500,500i,600,600i,700,700i,800,800i,900,900i" id="u-page-google-font" rel="stylesheet"/>
<!-- CSS -->
<link href="https://digital-justice.com/all.css" rel="stylesheet" type="text/css"/>
<link href="https://digital-justice.com/small.css" media="screen and (max-width: 48em)" rel="stylesheet"/>
<!-- Meta tags -->
<!-- Primary Meta Tags -->
<title>Facebook ber om ursäkt för att ha klassificerat svarta män som primater</title>
<meta content="Facebook ber om ursäkt för att ha klassificerat svarta män som primater" name="title"/>
<meta content="Man kan aldrig garantera att en AI levererar några hemska bieffekter, men Facebooks historia av rasistiska övergrepp gör det troligt att det här misstaget inte blir deras sista." name="description"/>
<!-- FontAwesome -->
<link href="https://digital-justice.com/icons/fontawesome-free-5.13.0-web/css/all.css" rel="stylesheet" type="text/css"/>
<!-- Open Graph / Facebook -->
<meta content="website" property="og:type"/>
<meta content="https://digital-justice.com/" property="og:url"/>
<meta content="Facebook ber om ursäkt för att ha klassificerat svarta män som primater" property="og:title"/>
<meta content="Man kan aldrig garantera att en AI levererar några hemska bieffekter, men Facebooks historia av rasistiska övergrepp gör det troligt att det här misstaget inte blir deras sista." property="og:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="og:image"/>
<!-- Twitter -->
<meta content="summary_large_image" property="twitter:card"/>
<meta content="https://digital-justice.com/" property="twitter:url"/>
<meta content="Facebook ber om ursäkt för att ha klassificerat svarta män som primater" property="twitter:title"/>
<meta content="Man kan aldrig garantera att en AI levererar några hemska bieffekter, men Facebooks historia av rasistiska övergrepp gör det troligt att det här misstaget inte blir deras sista." property="twitter:description"/>
<meta content="https://digital-justice.com/images/data-sovereignty-nologo.png" property="twitter:image"/>
<!-- Favicon -->
<!-- Favicon -->
<link href="https://digital-justice.com/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://digital-justice.com/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://digital-justice.com/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://digital-justice.com/icons/site.webmanifest" rel="manifest"/>
</head>
<body>
<header>
<nav>
<a href="../index.html"><i class="fas fa-home"></i> Hem</a>
<a href="../rights.html">Digitala rättigheter</a>
<a href="index.html">Artiklar</a>
<div id="language-picker"></div>
<a class="hamburger" href="javascript:void(0)" onclick="openHamburger()">
<i class="fa fa-bars"></i>
</a>
</nav>
<script src="https://digital-justice.com/js/open-hamburger.js"></script>
</header>
<main>
<section>
<article>
<h1>Facebook ber om ursäkt för att ha klassificerat svarta män som primater</h1>
<p>Detta är en autentisk artikel skriven av <a href="https://matrix.to/#/@bramvdnheuvel:nltrix.net">BramvdnHeuvel</a>.</p>
<p>Beräknad lästid: <img class="icon" src="https://digital-justice.com/images/clock.svg"/> 2 minuter.</p>
</article>
</section>
<section>
<article>
<div>
<h1>Facebook ber om ursäkt för att ha klassificerat svarta män som primater</h1>
<p>Artificiell intelligens kan ha rasistiska fördomar. <a href="https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html" target="_blank">Kaukasiska ansikten har 10 till 100 gånger större sannolikhet att bli korrekt igenkända och identifierade</a> än afroamerikanska ansikten och asiatiska ansikten, vilket redan har lett till <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" target="_blank">felaktiga anklagelser, arresteringar och till och med fängelsestraff</a> på grund av att en artificiell intelligens inte kunde matcha ett icke-vitt ansikte korrekt.</p>
<p>Många elever har upplevt detta på nära håll under pandemin. Många företag som <a href="https://proctorio.com/" target="_blank">Proctorio</a> har gjort stora framgångar på universitet och skolor, där lärare instruerar sina elever att installera programvara som kontrollerar om de gör ett prov ärligt. Programvaran var mer benägen att anklaga färgade personer för fusk eftersom <a href="https://micky.com.au/proctorio-test-software-fails-to-detect-people-of-color/" target="_blank">programvaran inte kunde känna igen deras ansikten</a>. Sådan programvara har visat sig <a href="https://www.technologyreview.com/2020/08/07/1006132/software-algorithms-proctoring-online-tests-ai-ethics/" target="_blank">stärka vit överhöghet, sexism, ableism och transfobi</a>.</p>
<h2>Facebooks misstag</h2>
<p>Facebooks ursäkt gällde svarta män i sammandrabbningar med vita civila och poliser, <a href="https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html" target="_blank"> enligt New York Times</a>. En AI för bildigenkänning klassificerade klippen som filmer av apor eller primater, trots att videorna inte hade något att göra med något av dem.</p>
<p>Hur kan det här hända? En bias i en artificiell intelligens är vanligtvis ett resultat av en partisk träningsuppsättning. Som Joy Buolamwini förklarar i <a href="https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms#t-257110" target="_blank">hennes TED-talk</a>, där hon förklarar hur en programvara för ansiktsigenkänning inte kunde känna igen hennes ansikte. På samma sätt kan en datamängd <a href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html" target="_blank">där över 80 procent av ansiktena är vita</a> ha svårare att känna igen människor med olika hudfärg och kanske tillgripa att klassificera dessa ansikten som något som ligger nära en människa - som apor och andra primater.</p>
<p>En liknande skandal som Facebooks senaste misstag inträffade 2015 när Google <a href="https://eu.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/">av misstag identifierade svarta människor som gorillor i Google Photos</a>. Men i stället för att ändra den artificiella intelligensen gjorde <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" target="_blank">Google Photos sig av med ord som "gorilla", "chimpans", "chimpans" och "apa". Även om detta innebär att människor inte längre kommer att identifieras som apor på Google Photos, tyder det på att de underliggande problemen med den intelligenta intelligensen inte har åtgärdats ännu.</a></p>
<h2>Facebooks rasistiska missförhållanden</h2>
<p>Även om Facebooks AI:s misstag kommer från en underliggande fråga som spelar på en samhällelig nivå har Facebook ett register över missbruk, ofta rasistiska.</p>
<ul>
<li>Instagram-användare vars aktivitet tydde på att de var svarta hade 50 % högre risk att få sina konton automatiskt inaktiverade. <a href="https://www.nbcnews.com/tech/tech-news/facebook-management-ignored-internal-research-showing-racial-bias-current-former-n1234746" target="_blank">Forskarna fick besked av sina överordnade att stoppa forskningen och hålla tyst om den</a>;</li>
<li>Mark Zuckerberg, Facebooks vd, <a href="https://gizmodo.com/mark-zuckerberg-asks-racist-facebook-employees-to-stop-1761272768" target="_blank">har varit tvungen att offentligt be anställda att sluta stryka över Black Lives Matter-slogans</a>;</li>
<li>Facebook <a href="https://www.nytimes.com/2021/08/11/technology/facebook-soccer-racism.html" target="_blank"> misslyckades med att stävja rasistiska kränkningar av Englands fotbollsspelare</a>;</li>
<li>Flera skrämmande <a href="https://medium.com/@blindfb2020/facebook-empowers-racism-against-its-employees-of-color-fbbfaf55ab76" target="_blank">berättelser om rasism och fanatism bland Facebooks anställda</a> har rapporterats anonymt.</li>
</ul>
<p>Exempel som dessa lämnar gott om utrymme för att undra hur uppriktigt Facebook tar primatfelmatchningen - och för att undra om ursäkten helt enkelt är en PR-åtgärd för att förhindra ytterligare kontroverser.</p>
<h2>Vad kan vi göra åt det?</h2>
<p>Bildigenkänning är ett mycket användbart verktyg som kan hjälpa oss att förbättra vårt dagliga liv, men innovation får inte åtföljas av diskriminering eller förstärkning av bigotthet. Klassificeringen av en människa som en apa är av en sådan förnedring, och det är inget annat än uppenbart att Facebook som företag bör hållas ansvarigt.</p>
<p>Det är bara trivialt att en enkel algoritm kan leda till stora konsekvenser på en stor plattform, och därför bör algoritmer behandlas på samma sätt. En algoritm för ansiktsigenkänning bör inte helt enkelt vara något man bara kan kasta på miljontals människor, och att kategorisera tusentals människor i gorillaavdelningen är lika oacceptabelt som att offentligt fördöma dessa människor som apor.</p>
<p>Låt inte en ursäkt räcka, särskilt inte för ett företag som har ett sådant track record av rasistiska övergrepp.</p>
</div>
</article>
</section>
</main>
<footer>
<p>Den här webbplatsen grundades av <a href="https://noordstar.me/">BramvdnHeuvel</a>. Här finns <a href="https://github.com/BramvdnHeuvel/Digital-Justice">källkoden.</a><br/> Du kan kontakta dem per <a href="mailto:hello@digital-justice.com">mejl</a> eller på <a href="https://matrix.to/#/#digital-justice:noordstar.me">Matrix</a>.</p>
<script src="https://digital-justice.com/js/expand-iframes.js"></script>
<script src="https://digital-justice.com/js/language-picker.js"></script>
</footer>
</body>
</html>
